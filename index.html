<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Albert Clapés — Curriculum Vitae</title>
  <style>
    body { font-family: Arial, Helvetica, sans-serif; line-height: 1.35; margin: 24px; max-width: 980px; }
    header { border-bottom: 1px solid #ccc; padding-bottom: 12px; margin-bottom: 16px; }
    nav a { margin-right: 12px; }
    h1 { margin: 0 0 6px 0; }
    h2 { border-top: 1px solid #eee; padding-top: 14px; margin-top: 22px; }
    .meta { color: #333; }
    .small { font-size: 0.95em; color: #444; }
    ul { margin-top: 8px; }
    li { margin-bottom: 8px; }
    .tag { font-size: 0.9em; color: #555; }
    .note { background: #fafafa; border: 1px solid #eee; padding: 10px; }
    .pubtag{
      display:inline-block;
      padding:2px 6px;
      margin-right:8px;
      border-radius:3px;
      font-size:0.85em;
      font-weight:bold;
      color:#fff;
      vertical-align:baseline;
    }
    .pubtag.journal{ background:#2a7; }
    .pubtag.conf{ background:#27a; }
  </style>
</head>

<body>
  <header>
    <h1>Albert Clapés, PhD</h1>
    <div class="meta">
      Serra Húnter Lecturer (Professor Lector Serra Húnter), Faculty of Mathematics and Computer Science, University of Barcelona (UB)
      <!-- Start date in CV: 01/02/2023. Include it only if you want it public. -->
    </div>
    <div class="small">
      <strong>ORCID:</strong> <a href="https://orcid.org/0000-0002-4089-9060">0000-0002-4089-9060</a> ·
      <strong>Scopus Author ID:</strong> 55329424200 ·
      <strong>ResearcherID:</strong> NES-3617-2025 ·
      <strong>Google Scholar:</strong>
      <a href="https://scholar.google.com/citations?user=n4BtpPsAAAAJ&hl=en">Profile</a>
      (+1.9K citations, h-index 21, i10-index 23)
      <!-- OPTIONAL (add later if you want):
      · Email: <a href="mailto:YOUR_EMAIL">YOUR_EMAIL</a>
      · Google Scholar: <a href="YOUR_SCHOLAR_URL">Profile</a>
      · GitHub: <a href="YOUR_GITHUB_URL">YOUR_HANDLE</a>
      -->
    </div>
    <div class="note small">
      Research interests: Computer Vision, Machine Learning, and AI for understanding human behavior (actions/gestures and beyond:
      psychological states, intention anticipation, efficient perception via multimodality, pretraining, and multi-task distillation).
      <!-- From narrative summary in the CV -->
    </div>

    <nav class="small">
      <a href="#publications">Publications</a>
      <a href="#projects">Projects</a>
      <a href="#phd">PhD Thesis Supervision</a>
      <a href="#teaching">Teaching</a>
      <a href="#merits">Other Scientific Merits</a>
    </nav>
  </header>

  <section id="publications">
    <h2>Publications</h2>
    <p class="small">
      This is a selection of the latest and most relevant publications. For <strong>journals</strong>, I report Journal Impact Factor (JIF/JCR) as stated in <a href="https://clarivate.com/academia-government/scientific-and-academic-research/research-discovery-and-referencing/web-of-science/">WoS</a>; for <strong>peer-reviewed conference proceedings</strong>, I report <a href="https://scie.lcc.uma.es:8443/">GGS class</a>.
      Links point to open-access or publisher pages.
    </p>

    <h3>2026</h3>
    <ul>
      <li>
        <span class="pubtag conf">CONF. PROCEEDINGS</span> Xarles A, Escalera S, Clapés A. <b>AdaSpot: Spend Resolution Where It Matters for Precise Event Spotting</b>.
        CVPR 2026.
        <span class="tag">GGS Class 1 (A++). AR 25.42% (source).</span>
        Paper (just accepted)
      </li>
      <li>
        <span class="pubtag conf">CONF. PROCEEDINGS</span> Pujol-Perich D, Clapés A, Damen D, Escalera S, Wray M. <b>Beyond Caption-Based Queries in Video Moment Retrieval</b>.
        CVPR 2026.
        <span class="tag">GGS Class 1 (A++). AR 25.42% (source).</span>
        Paper (just accepted)
      </li>
    </ul>
    
    <h3>2025</h3>
    <ul>
      <li>
        <span class="pubtag conf">CONF. PROCEEDINGS</span> Pujol-Perich D, Escalera S, Clapés A. <b>Sparse-Dense Side-Tuner for efficient Video Temporal Grounding (SDST)</b>.
        ICCV 2025.
        <span class="tag">GGS Class 1 (A++). AR 24.03% (<a href="https://media.eventhosts.cc/Conferences/ICCV2025/iccv25_main_program.pdf">source</a>).</span>
        <a href="https://openaccess.thecvf.com/content/ICCV2025/html/Pujol-Perich_Sparse-Dense_Side-Tuner_for_efficient_Video_Temporal_Grounding_ICCV_2025_paper.html">Paper</a>
      </li>
      <li>
        <span class="pubtag conf">CONF. PROCEEDINGS</span> Xarles A, Escalera S, Moeslund TB, Clapés A. <b>Action Valuation in Sports: A Survey</b>. CVPR Workshops 2025.
        <span class="tag">Workshop of GGS Class 1 (A++).</span>
        <a href="https://ieeexplore.ieee.org/document/11148046">IEEE</a>
      </li>
      <li>
        <span class="pubtag conf">CONF. PROCEEDINGS</span> Dalal M, Xarles A, Cioppa A, Giancola S, Van Droogenbroeck M, Ghanem B, Clapés A, Escalera S, Moeslund TB.
        <b>Action Anticipation from SoccerNet Football Video Broadcasts</b>. CVPR Workshops 2025.
        <span class="tag">Workshop of GGS Class 1 (A++).</span>
        <a href="https://ieeexplore.ieee.org/document/11147467">IEEE</a>
      </li>
      <li>
        <span class="pubtag conf">CONF. PROCEEDINGS</span> Pujol-Perich D, Clapés A, Escalera S. <b>SADA: Semantic Adversarial Unsupervised Domain Adaptation for Temporal Action Localization</b>.
        WACV 2025.
        <span class="tag">GGS Class 2. AR 37.8% (<a href="https://wacv2025.thecvf.com/wp-content/uploads/2025/02/WACV-2025-Program.pdf">source</a>).</span>
        <a href="https://ieeexplore.ieee.org/document/10943847">IEEE</a>
      </li>
    </ul>

    <h3>2024</h3>
    <ul>
      <li>
        <span class="pubtag conf">CONF. PROCEEDINGS</span> Xarles A, Escalera S, Moeslund TB, Clapés A. <b>T-DEED: Temporal-Discriminability Enhancer Encoder-Decoder for Precise Event Spotting in Sports Videos</b>.
        CVPR Workshops 2024.
        <span class="tag">Workshop of GGS Class 1 (A++).</span>
        <a href="https://ieeexplore.ieee.org/document/10677971">IEEE</a>
      </li>
      <li>
        <span class="pubtag journal">JOURNAL</span> Cioppa A, Giancola S, Somers V, …, Clapés A, … <b>SoccerNet 2023 challenges results</b>. Sports Engineering, 2024.
        <span class="tag">JIF 1.4 (JCR).</span>
        <a href="https://link.springer.com/article/10.1007/s12283-024-00466-4">Springer</a>
      </li>
    </ul>

    <h3>2023</h3>
    <ul>
      <li>
        <span class="pubtag conf">CONF. PROCEEDINGS</span> Zhou B, Chen Z, Clapés A, Wan J, Liang Y, Escalera S, Lei Z, Zhang D.
        <b>Gloss-free sign language translation: Improving from visual-language pretraining (GFSLT-VLP)</b>.
        ICCV 2023.
        <span class="tag">GGS Class 1 (A++). AR 26.15% (<a href="https://iccv2023.thecvf.com/program.overview-97.php">source</a>).</span>
        <a href="https://ieeexplore.ieee.org/document/10377463">IEEE</a>
      </li>
      <li>
        <span class="pubtag conf">CONF. PROCEEDINGS</span> Xarles A, Escalera S, Moeslund TB, Clapés A. <b>Astra: An action spotting transformer for soccer videos</b>.
        MMSports 2023.
        <a href="https://dl.acm.org/doi/10.1145/3606038.3616153">ACM</a>
      </li>
      <li>
        <span class="pubtag journal">JOURNAL</span> Selva J, Johansen AS, Escalera S, Nasrollahi K, Moeslund TB, Clapés A.
        <b>Video Transformers: A Survey</b>. IEEE TPAMI, 2023.
        <span class="tag">JIF 20.8 (JCR), Q1; position 2/197 (CS AI).</span>
        <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10041724">IEEE</a>
      </li>
    </ul>

    <h3>2022</h3>
    <ul>
      <li>
        <span class="pubtag journal">JOURNAL</span> Tarling P, Cantor M, Clapés A, Escalera S.
        <b>Deep learning with self-supervision and uncertainty regularization to count fish in underwater images</b>.
        PLoS ONE, 2022.
        <span class="tag">JIF 3.7 (JCR), Q2.</span>
        <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0267759">PLOS</a>
      </li>
    </ul>

    <h3>2021</h3>
    <ul>
      <li>
        <span class="pubtag conf">CONF. PROCEEDINGS</span> Clapés A, Curto D, Selva J, …, Escalera S. <b>Dyadformer: A Multi-modal Transformer for Long-Range Modeling of Dyadic Interactions</b>.
        ICCV Workshops 2021.
        <span class="tag">GGS Class 1 (A++).</span>
        <a href="https://ieeexplore.ieee.org/document/9607463">IEEE</a>
      </li>
      <li>
        <span class="pubtag conf">CONF. PROCEEDINGS</span> Palmero C, Selva J, Smeureanu S, …, Escalera S.
        <b>Context-Aware Personality Inference in Dyadic Scenarios: Introducing the UDIVA Dataset</b>.
        WACV Workshops 2021.
        <span class="tag">GGS Class 2.</span>
        <a href="https://link.springer.com/chapter/10.1007/978-3-030-11012-3_40">Springer</a>
      </li>
    </ul>

    <h3>Earlier years</h3>
    <ul>
      <li>
        <span class="pubtag conf">CONF. PROCEEDINGS</span> Jacques-Junior JCS, Morral C, Escalera S, Clapés A. <b>ChaLearn LAP 2020 Challenge on Identity-preserved Human Detection: Dataset and Results</b>.
        FG 2020.
        <span class="tag">GGS Class 2.</span>
        <a href="https://ieeexplore.ieee.org/document/9320283">IEEE</a>
      </li>
      <li>
        <span class="pubtag journal">JOURNAL</span> Ofodile I, Helmi A, Clapés A, …, Anbarjafari G. <b>Action Recognition Using Single-Pixel Time-of-Flight Detection</b>.
        Entropy, 2019.
        <span class="tag">JIF 2.494 (JCR), Q2.</span>
        <a href="https://www.mdpi.com/1099-4300/21/4/414">MDPI</a>
      </li>
      <li>
        <span class="pubtag journal">JOURNAL</span> Clapés A, Pardo À, Pujol-Vila O, Escalera S.
        <b>Action detection fusing multiple Kinects and a WIMU: an application to in-home assistive technology for the elderly</b>.
        Machine Vision and Applications, 2018.
        <span class="tag">JIF 1.788 (JCR), Q2.</span>
        <a href="https://link.springer.com/article/10.1007/s00138-018-0931-1">Springer</a>
      </li>
      <li>
        <span class="pubtag journal">JOURNAL</span> Palmero C, Clapés A, Bahnsen C, Mogelmose A, Moeslund TB.
        <b>Multi-modal RGB-Depth-Thermal Human Body Segmentation</b>.
        IJCV, 2016.
        <span class="tag">JIF 8.222 (JCR), Q1.</span>
        <a href="https://link.springer.com/article/10.1007/s11263-016-0901-x">Springer</a>
      </li>
      <li>
        <span class="pubtag conf">CONF. PROCEEDINGS</span> Cepero Á, Clapés A, Escalera S. <b>Automatic non-verbal communication skills analysis: A quantitative evaluation</b>.
        AI Communications, 2015.
        <span class="tag">JIF 0.364 (JCR), Q4.</span>
        <a href="https://journals-sagepub-com.sire.ub.edu/doi/10.3233/AIC-140617">Link</a>
      </li>
      <li>
        <span class="pubtag conf">CONF. PROCEEDINGS</span> Reyes M, Clapés A, Ramírez J, Revilla JR, Escalera S.
        <b>Automatic digital biometry analysis based on depth maps</b>.
        Computers in Industry, 2013.
        <span class="tag">JIF 1.457 (JCR), Q3.</span>
        <a href="https://www.sciencedirect.com/science/article/abs/pii/S0166361513000924">ScienceDirect</a>
      </li>
      <li>
        <span class="pubtag journal">JOURNAL</span> Clapés A, Reyes M, Escalera S.
        <b>Multi-modal user identification and object recognition surveillance system</b>.
        Pattern Recognition Letters, 2013.
        <span class="tag">JIF 1.062 (JCR), Q3.</span>
        <a href="https://www.sciencedirect.com/science/article/abs/pii/S0167865512004047">ScienceDirect</a>
      </li>
    </ul>

    <p class="small">
      <!-- EASY EDIT: If you want the full “Top-20 contributions” list exactly as in the AQU CV, you can paste the remaining entries here. -->
    </p>
  </section>

  <section id="projects">
    <h2>Projects</h2>
    The following list is a selection of the latest and most relevant projects.

    <h3>European Projects</h3>
    <ul>
      <li>
        <b>Diversibus Viis Plurima Solvo (DVPS)</b> — HORIZON-CL4-2024-HUMAN-03, Horizon Europe,
        Grant: <b>101213369</b>, Period: 01/07/2025–30/06/2029.
        <span class="tag">Role: project member (UB partnership).</span>
      </li>
      <li>
        <b>HappyMums</b> — HORIZON-HLTH-2021-STAYHLTH-01, Horizon Europe,
        Grant: <b>101057390</b>, Period: 01/11/2022–31/10/2026.
        <span class="tag">Role: project member (UB partnership).</span>
      </li>
      <li>
        <b>Youth-GEMs</b> — HORIZON-HLTH-2021-STAYHLTH-01, Horizon Europe,
        Grant: <b>101070421</b>, Period: 01/06/2022–31/05/2027.
        <span class="tag">Role: project member (UB partnership).</span>
      </li>
    </ul>

    <h3>National Projects</h3>
    <ul>
      <li>
        <b>Hacia una IA segura y confiable</b> — Proyectos de Generación de Conocimiento 2022 (Investigación No Orientada), Ministerio de Ciencia e Innovación,
        Ref: <b>PID2022-136436NB-I00</b>, Period: 01/09/2023–31/08/2026.
        <span class="tag">Role: project member.</span>
      </li>
    </ul>
    
    <h3>Regional Projects (Catalonia)</h3>
    <ul>
      <li>
        <b>Noves dianes terapèutiques en la depressió: el paper de la percepció situacional</b> — La Marató de TV3 – Salut Mental (2021), Fundació La Marató de TV3,
        Ref: <b>433/U/2022</b>, Period: 15/03/2023–14/03/2026.
        <span class="tag">Role: project member.</span>
      </li>
      
    </ul>

    <h3>Transference / Industry Collaboration Projects</h3>
    <ul>
      <li>
        <b>Multi-Modal Knowledge Distillation for Improved Visual Understanding</b> — Huawei,
        Ref: FBG 313528, Period: 05/12/2025–04/12/2027.
        <span class="tag">Funding: €251,406.</span>
        <span class="tag">Role: Principal Investigator.</span>
      </li>
    
      <li>
        <b>A Virtual Clothing Try-On System Based on 3D Body and Garment Reconstruction and Animation</b> — Indústria del Coneixement 2024 – Producte (Modalitat B), Generlitat de Catalunya,
        Ref: 2024 PROD 00013, Period: 02/12/2024–01/06/2026.
        <span class="tag">Funding: €150,000.</span>
        <span class="tag">Role: Project member.</span>
      </li>
    
      <li>
        <b>NEFA YouAddict EIT Digital Project</b> — EIT Digital 2024, 
        Ref: FBG 23395, Period: 01/01/2024–30/06/2024.
        <span class="tag">Funding: €115,000.</span>
        <span class="tag">Role: Project member.</span>
      </li>
    
      <li>
        <b>Research Services on Fashion Recommendation and Retrieval</b> — YouAddict Srl,
        Ref: FBG 312945, Period: 06/09/2024–05/03/2025.
        <span class="tag">Funding: €40,000.</span>
        <span class="tag">Role: Project member.</span>
      </li>
    
      <li>
        <b>Consultancy on Milestone AI Research Strategy</b> — Milestone Systems S/A,
        Ref: FBG 312249; Period: 08/05/2023–07/12/2023.
        <span class="tag">Funding: €7,317.</span>
        <span class="tag">Role: Project member.</span>
      </li>
    </ul>

    <p class="small">
      <!-- EASY EDIT: You can add “selected outcomes” (software, datasets, open-source links) under each project. -->
    </p>
  </section>

  <section id="phd">
    <h2>Directed PhD Thesis Supervision</h2>
    <ul>
      <li>
        <b>Completed (1):</b>
        Javier Selva (University of Barcelona, Dec 19th 2023).
      </li>
      <li>
        <b>Ongoing (3):</b>
        Artur Xarles (University of Barcelona);
        David Pujol-Perich (University of Barcelona);
        Michal Choinski (industrial PhD: University of Barcelona × Restb.ai).
      </li>
    </ul>
    <p class="small">
      <!-- Source: narrative mentions “Director d’1 tesi doctoral (+2 en curs)”. -->
    </p>
  </section>

  <section id="teaching">
    <h2>Teaching (summary)</h2>
    <ul>
      <li>
        <b>University teaching load:</b> 3.375 full-time equivalent years; 135 hours theoretical + 566.5 hours practical
        (700+ total hours reported). 
      </li>
      <li>
        <b>Undergraduate teaching (UB):</b> Computer Science / Mathematics degrees (including double degree).
        Courses taught include: Programming I, Programming II, Data Structures, Software Design, Integrated Software Project.
      </li>
      <li>
        <b>Master teaching:</b> Video Analysis at Interuniversity Master in Computer Vision (UAB, UPC, UPF, UB, and UOC) in 2023/24 and 2024/25.
      </li>
      <li>
        <b>Supervision:</b> 12× BSc theses (TFG) and 4× MSc theses (TFM).
      </li>
      <li>
        <b>Teaching innovation:</b> “Xatbot educativa gamificada…” (RIMDA, UB), Ref: 2023PMD-UB/031 (01/09/2023–30/07/2024).
      </li>
      <li>
        <b>Invited teaching:</b> Université Paris-Saclay (Computer Vision master), two lectures in 2021/22 and 2022/23.
      </li>
    </ul>
  </section>

  <section id="merits">
    <h2>Other Scientific Merits</h2>

    <h3>Academic trajectory & recognition</h3>
    <ul>
      <li>
        <strong>Extraordinary PhD Award</strong> — PhD, University of Barcelona (2019). 
        Dissertation: “Learning to recognize human actions: from hand-crafted to deep-learning based visual representations”. 
        <em>Cum Laude</em>; International Mention.
      </li>
      <li><strong>Accreditations for University Professorship:</strong></li>
      <ul>
        <li>ANECA “Profesor/a Contratado/a Doctor/a” (2025)</li>
        <li>AQU “Professorat Lector” (2020)</li>
      </ul>
    </ul>

    <h3>Memberships and leadership</h3>
    <ul>
      <li>Member of ELLIS. <a href="https://ellis.eu/members/members-list">Link</a></li>
      <li>Vice-president of the IAPR P&amp;P committee. <a href="https://iapr.org/committees/publications-and-publicity-committee/">Link</a></li>
      <li>Area Chair: NeurIPS 2024.</li>
      <li>SGR 2021 team member.</li>
      <li>Co-IP of TECSAM reasearch group (#56 Human Behavior Understanding using Computer Vision and AI). <a href="https://tecsam.org/about/">Link</a></li>
    </ul>

    <h3>Transference & Dissemination activities</h3>
    <ul>
      <li>Scientific advisory</li>
        <ul>
          <li>Scientific Advisor and Consultant for the BitSpace spin-off in the AI Accelerator programme (Xarxa RDI-IA, Generalitat of Catalonia). <a href="https://xarxardi-ia.cat/tercera-edicio-de-lai-accelerator/">Link</a>
        </ul>
      <li>Scientific Advisory, AI-Accelerator (BitSpace). <a href=https://xarxardi-ia.cat/tercera-edicio-de-lai-accelerator/>Link</a></li>
      <li>(Co-)organization of International Conference Workshops:
        <ul>
          <li>2nd International Workshop & Challenge on Subtle Visual Computing @ CVPR26</li>
          <li>12th International Workshop on Computer Vision in Sports (CVsports) @ CVPR26</li>
          <li>Understanding Social Behavior in Dyadic and Small Group Interactions Challenge @ ICCV21</li>
          <li>ChaLearn LAP Workshop @ ICPR16</li>
          <li>ChaLearn LAP Workshop @ ECCV16</li>          
        </ul>
      <li>Organization of Challenges (and associated Workshop):
        <ul>
          <li>SoccerNet's Ball Action Anticipation Challenge (associated to CVsports @ CVPR26)</li>
          <li>Chalearn's Understanding Social Behavior in Dyadic and Small Group Interactions Challenge (associated to Understanding Social Behavior in Dyadic and Small Group Interactions Challenge @ ICCV21)</li>
          <li>Chalearn's Identity-preserved Human Detection</li>
          <li>ChaLearn's First Impressions Challenge (associated to ChaLearn LAP Workshop @ ICPR16 and ChaLearn LAP Workshop @ ECCV16)</li>
        </ul>
      </li>
      <li>Outreach and Dissemination activities:
        <ul>
          <li>Organizer, <a href="https://mat.ub.edu/matapps/activitats/xerrades/les-maquines-tambe-sequivoquen/">Las màquines intel·ligents també s’equivoquen"</a> (Xerrades-Taller; UB, 2025)</li>
          <li>Scientific Committee Member, "Anàlisi automàtica d’imatges mèdiques" (Xerrades-Taller; UB, 2014)</li>
          <li>Co-organizer, "Les màquines: sistemes intel·ligents" (Campus Ítaca; UAB; 2012–2014)</li>
          <li>Scientific Committee Member, "Màquines que analitzen el comportament humà: la interacció entre l’home i la màquina" (Xerrades-Taller; UB, 2014)</li>
        </ul>
      </li>
    </ul>

    <h3>International mobility</h3>
    <ul>
      <li>
        Postdoctoral: Aalborg University (Denmark). Period: 01/04/2021–31/01/2023.
      </li>
      <li>
        Predoctoral: Aalborg University (Denmark). Period: 28/06/2018–28/09/2018.
      </li>
    </ul>
  </section>

  <footer class="small" style="margin-top: 28px; border-top: 1px solid #ccc; padding-top: 10px;">
    Last updated: Jan 13th, 2026
    <br />
    <!-- OPTIONAL: Add a link to a PDF version of your CV in the repo. -->
  </footer>
</body>
</html>
