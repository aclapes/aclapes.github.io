<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Albert Clapés Sintes — Curriculum Vitae</title>
  <style>
    body { font-family: Arial, Helvetica, sans-serif; line-height: 1.35; margin: 24px; max-width: 980px; }
    header { border-bottom: 1px solid #ccc; padding-bottom: 12px; margin-bottom: 16px; }
    nav a { margin-right: 12px; }
    h1 { margin: 0 0 6px 0; }
    h2 { border-top: 1px solid #eee; padding-top: 14px; margin-top: 22px; }
    .meta { color: #333; }
    .small { font-size: 0.95em; color: #444; }
    ul { margin-top: 8px; }
    li { margin-bottom: 8px; }
    .tag { font-size: 0.9em; color: #555; }
    .note { background: #fafafa; border: 1px solid #eee; padding: 10px; }
  </style>
</head>

<body>
  <header>
    <h1>Albert Clapés Sintes</h1>
    <div class="meta">
      Professor Lector (Serra Húnter), Faculty of Mathematics and Computer Science, University of Barcelona (UB)
      <!-- Start date in CV: 01/02/2023. Include it only if you want it public. -->
    </div>
    <div class="small">
      ORCID: <a href="https://orcid.org/0000-0002-4089-9060">0000-0002-4089-9060</a> ·
      Scopus Author ID: 55329424200 ·
      ResearcherID: NES-3617-2025
      <!-- OPTIONAL (add later if you want):
      · Email: <a href="mailto:YOUR_EMAIL">YOUR_EMAIL</a>
      · Google Scholar: <a href="YOUR_SCHOLAR_URL">Profile</a>
      · GitHub: <a href="YOUR_GITHUB_URL">YOUR_HANDLE</a>
      -->
    </div>
    <div class="note small">
      Research interests: Computer Vision, Machine Learning, and AI for understanding human behavior (actions/gestures and beyond:
      psychological states, intention anticipation, efficient perception via multimodality, pretraining, and multi-task distillation).
      <!-- From narrative summary in the CV -->
    </div>

    <nav class="small">
      <a href="#publications">Publications</a>
      <a href="#projects">Projects</a>
      <a href="#phd">PhD Thesis Supervision</a>
      <a href="#teaching">Teaching</a>
      <a href="#merits">Other Scientific Merits</a>
    </nav>
  </header>

  <section id="publications">
    <h2>Publications (selected list with impact measures)</h2>
    <p class="small">
      Notes: For journals, I report Journal Impact Factor (JIF/JCR) as stated in the CV; for conferences, I report GGS class where provided.
      Links point to open-access or publisher pages, as listed in the CV.
    </p>

    <h3>2025</h3>
    <ul>
      <li>
        Pujol-Perich D, Escalera S, Clapés A. <b>Sparse-Dense Side-Tuner for efficient Video Temporal Grounding (SDST)</b>.
        ICCV 2025.
        <span class="tag">GGS Class 1 (A++).</span>
        <a href="https://openaccess.thecvf.com/content/ICCV2025/html/Pujol-Perich_Sparse-Dense_Side-Tuner_for_efficient_Video_Temporal_Grounding_ICCV_2025_paper.html">Paper</a>
      </li>
      <li>
        Xarles A, Escalera S, Moeslund TB, Clapés A. <b>Action Valuation in Sports: A Survey</b>. CVPR Workshops 2025.
        <span class="tag">GGS Class 1 (A++).</span>
        <a href="https://ieeexplore.ieee.org/document/11148046">IEEE</a>
      </li>
      <li>
        Dalal M, Xarles A, Cioppa A, Giancola S, Van Droogenbroeck M, Ghanem B, Clapés A, Escalera S, Moeslund TB.
        <b>Action Anticipation from SoccerNet Football Video Broadcasts</b>. CVPR Workshops 2025.
        <span class="tag">GGS Class 1 (A++).</span>
        <a href="https://ieeexplore.ieee.org/document/11147467">IEEE</a>
      </li>
      <li>
        Pujol-Perich D, Clapés A, Escalera S. <b>SADA: Semantic Adversarial Unsupervised Domain Adaptation for Temporal Action Localization</b>.
        WACV 2025.
        <span class="tag">GGS Class 2.</span>
        <a href="https://ieeexplore.ieee.org/document/10943847">IEEE</a>
      </li>
    </ul>

    <h3>2024</h3>
    <ul>
      <li>
        Xarles A, Escalera S, Moeslund TB, Clapés A. <b>T-DEED: Temporal-Discriminability Enhancer Encoder-Decoder for Precise Event Spotting in Sports Videos</b>.
        CVPR Workshops 2024.
        <span class="tag">GGS Class 1 (A++).</span>
        <a href="https://ieeexplore.ieee.org/document/10677971">IEEE</a>
      </li>
      <li>
        Cioppa A, Giancola S, Somers V, …, Clapés A, … <b>SoccerNet 2023 challenges results</b>. Sports Engineering, 2024.
        <span class="tag">JIF 1.4 (JCR).</span>
        <a href="https://link.springer.com/article/10.1007/s12283-024-00466-4">Springer</a>
      </li>
    </ul>

    <h3>2023</h3>
    <ul>
      <li>
        Zhou B, Chen Z, Clapés A, Wan J, Liang Y, Escalera S, Lei Z, Zhang D.
        <b>Gloss-free sign language translation: Improving from visual-language pretraining (GFSLT-VLP)</b>.
        ICCV 2023.
        <span class="tag">GGS Class 1 (A++).</span>
        <a href="https://ieeexplore.ieee.org/document/10377463">IEEE</a>
      </li>
      <li>
        Xarles A, Escalera S, Moeslund TB, Clapés A. <b>Astra: An action spotting transformer for soccer videos</b>.
        MMSports 2023.
        <a href="https://dl.acm.org/doi/10.1145/3606038.3616153">ACM</a>
      </li>
      <li>
        Selva J, Johansen AS, Escalera S, Nasrollahi K, Moeslund TB, Clapés A.
        <b>Video Transformers: A Survey</b>. IEEE TPAMI, 2023.
        <span class="tag">JIF 20.8 (JCR), Q1; position 2/197 (CS AI).</span>
        <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10041724">IEEE</a>
      </li>
    </ul>

    <h3>2022</h3>
    <ul>
      <li>
        Tarling P, Cantor M, Clapés A, Escalera S.
        <b>Deep learning with self-supervision and uncertainty regularization to count fish in underwater images</b>.
        PLoS ONE, 2022.
        <span class="tag">JIF 3.7 (JCR), Q2.</span>
        <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0267759">PLOS</a>
      </li>
    </ul>

    <h3>2021</h3>
    <ul>
      <li>
        Clapés A, Curto D, Selva J, …, Escalera S. <b>Dyadformer: A Multi-modal Transformer for Long-Range Modeling of Dyadic Interactions</b>.
        ICCV Workshops 2021.
        <span class="tag">GGS Class 1 (A++).</span>
        <a href="https://ieeexplore.ieee.org/document/9607463">IEEE</a>
      </li>
      <li>
        Palmero C, Selva J, Smeureanu S, …, Escalera S.
        <b>Context-Aware Personality Inference in Dyadic Scenarios: Introducing the UDIVA Dataset</b>.
        WACV Workshops 2021.
        <span class="tag">GGS Class 2.</span>
        <a href="https://link.springer.com/chapter/10.1007/978-3-030-11012-3_40">Springer</a>
      </li>
    </ul>

    <h3>Earlier (selected)</h3>
    <ul>
      <li>
        Jacques-Junior JCS, Morral C, Escalera S, Clapés A. <b>ChaLearn LAP 2020 Challenge on Identity-preserved Human Detection: Dataset and Results</b>.
        FG 2020.
        <span class="tag">GGS Class 2.</span>
        <a href="https://ieeexplore.ieee.org/document/9320283">IEEE</a>
      </li>
      <li>
        Ofodile I, Helmi A, Clapés A, …, Anbarjafari G. <b>Action Recognition Using Single-Pixel Time-of-Flight Detection</b>.
        Entropy, 2019.
        <span class="tag">JIF 2.494 (JCR), Q2.</span>
        <a href="https://www.mdpi.com/1099-4300/21/4/414">MDPI</a>
      </li>
      <li>
        Clapés A, Pardo À, Pujol-Vila O, Escalera S.
        <b>Action detection fusing multiple Kinects and a WIMU: an application to in-home assistive technology for the elderly</b>.
        Machine Vision and Applications, 2018.
        <span class="tag">JIF 1.788 (JCR), Q2.</span>
        <a href="https://link.springer.com/article/10.1007/s00138-018-0931-1">Springer</a>
      </li>
      <li>
        Palmero C, Clapés A, Bahnsen C, Mogelmose A, Moeslund TB.
        <b>Multi-modal RGB-Depth-Thermal Human Body Segmentation</b>.
        IJCV, 2016.
        <span class="tag">JIF 8.222 (JCR), Q1.</span>
        <a href="https://link.springer.com/article/10.1007/s11263-016-0901-x">Springer</a>
      </li>
      <li>
        Cepero Á, Clapés A, Escalera S. <b>Automatic non-verbal communication skills analysis: A quantitative evaluation</b>.
        AI Communications, 2015.
        <span class="tag">JIF 0.364 (JCR), Q4.</span>
        <a href="https://journals-sagepub-com.sire.ub.edu/doi/10.3233/AIC-140617">Link</a>
      </li>
      <li>
        Reyes M, Clapés A, Ramírez J, Revilla JR, Escalera S.
        <b>Automatic digital biometry analysis based on depth maps</b>.
        Computers in Industry, 2013.
        <span class="tag">JIF 1.457 (JCR), Q3.</span>
        <a href="https://www.sciencedirect.com/science/article/abs/pii/S0166361513000924">ScienceDirect</a>
      </li>
      <li>
        Clapés A, Reyes M, Escalera S.
        <b>Multi-modal user identification and object recognition surveillance system</b>.
        Pattern Recognition Letters, 2013.
        <span class="tag">JIF 1.062 (JCR), Q3.</span>
        <a href="https://www.sciencedirect.com/science/article/abs/pii/S0167865512004047">ScienceDirect</a>
      </li>
    </ul>

    <p class="small">
      <!-- EASY EDIT: If you want the full “Top-20 contributions” list exactly as in the AQU CV, you can paste the remaining entries here. -->
    </p>
  </section>

  <section id="projects">
    <h2>Projects</h2>

    <h3>European Projects</h3>
    <ul>
      <li>
        <b>Diversibus Viis Plurima Solvo (DVPS)</b> — Horizon Europe (HORIZON-CL4-2024-HUMAN-03),
        Grant: <b>101213369</b>, 01/07/2025–30/06/2029.
        <span class="tag">Role: project member (group of 8, UB).</span>
      </li>
      <li>
        <b>HappyMums</b> — Horizon Europe (HORIZON-HLTH-2021-STAYHLTH-01),
        Grant: <b>101057390</b>, 01/11/2022–31/10/2026.
        <span class="tag">Role: project member (UB group).</span>
      </li>
      <li>
        <b>Youth-GEMs</b> — Horizon Europe (HORIZON-HLTH-2021-STAYHLTH-01),
        Grant: <b>101070421</b>, 01/06/2022–31/05/2027.
        <span class="tag">Role: project member (UB group).</span>
      </li>
    </ul>

    <h3>National Projects</h3>
    <ul>
      <li>
        <b>Hacia una IA segura y confiable</b> — Ministerio de Ciencia e Innovación,
        Ref: <b>PID2022-136436NB-I00</b>, 01/09/2023–31/08/2026.
      </li>
      <li>
        <b>Noves dianes terapèutiques en la depressió: el paper de la percepció situacional</b> — Fundació La Marató de TV3,
        Ref: <b>433/U/2022</b>, 15/03/2023–14/03/2026.
      </li>
    </ul>

    <h3>Transference / Industry Collaboration Projects</h3>
    <ul>
      <li>
        <b>A Virtual Clothing try on System based on 3D Body and Garment reconstruction and animation</b>
        (Ref: 2024 PROD 00013), 02/12/2024–01/06/2026.
        <span class="tag">Funding: €150,000.</span>
        <!-- Company/partner names can be added if you want them public. -->
      </li>
      <li>
        <b>23395 NEFA YouAddict EIT Digital Project</b>, 01/01/2024–30/06/2024.
        <span class="tag">Funding: €115,000.</span>
      </li>
      <li>
        <b>Research services on Fashion Recommendation and Retrieval</b> (YouAddict Srl), 06/09/2024–05/03/2025.
        <span class="tag">Funding: €40,000.</span>
      </li>
      <li>
        <b>Consultancy on Milestone AI research strategy</b> (Milestone Systems S/A), 08/05/2023–07/12/2023.
        <span class="tag">Funding: €7,317.</span>
      </li>
      <li>
        <b>Anàlisi automàtica de marcadors a fisioteràpia</b> (Instituto de Fisioterapia Global Mézières, S.L.), 08/05/2013–07/12/2013.
        <span class="tag">Funding: €9,000.</span>
      </li>
    </ul>

    <p class="small">
      <!-- EASY EDIT: You can add “selected outcomes” (software, datasets, open-source links) under each project. -->
    </p>
  </section>

  <section id="phd">
    <h2>Directed PhD Thesis Supervision</h2>
    <ul>
      <li><b>Completed:</b> 1 PhD thesis directed. <span class="tag">(Details omitted here; add title/student/date if you want them public.)</span></li>
      <li><b>Ongoing:</b> 2 PhD theses in progress. <span class="tag">(Details omitted here; add as desired.)</span></li>
    </ul>
    <p class="small">
      <!-- Source: narrative mentions “Director d’1 tesi doctoral (+2 en curs)”. -->
    </p>
  </section>

  <section id="teaching">
    <h2>Teaching (summary)</h2>
    <ul>
      <li>
        <b>University teaching load:</b> 3.375 full-time equivalent years; 135 hours theoretical + 566.5 hours practical
        (700+ total hours reported). 
      </li>
      <li>
        <b>Undergraduate teaching (UB):</b> Computer Science / Mathematics degrees (including double degree).
        Courses taught include: Programming I, Programming II, Data Structures, Software Design, Integrated Software Project.
      </li>
      <li>
        <b>Master teaching:</b> Erasmus Mundus / interuniversity Master in Computer Vision (Video Analysis; English; UB/UPC shared).
      </li>
      <li>
        <b>Supervision:</b> 12 BSc theses (TFG), 4 MSc theses (TFM), 7 internships (as reported).
      </li>
      <li>
        <b>Teaching innovation:</b> “Xatbot educativa gamificada…” (RIMDA, UB), Ref: 2023PMD-UB/031 (01/09/2023–30/07/2024).
      </li>
      <li>
        <b>Invited teaching:</b> Université Paris-Saclay (Computer Vision master), two lectures in 2021/22 and 2022/23.
      </li>
    </ul>
  </section>

  <section id="merits">
    <h2>Other Scientific Merits</h2>

    <h3>Academic trajectory & recognition</h3>
    <ul>
      <li>
        PhD (University of Barcelona, 2019): “Learning to recognize human actions: from hand-crafted to deep-learning based visual representations”;
        Cum Laude; international mention; Extraordinary PhD Award (as stated in the CV).
      </li>
      <li>
        Accreditations: AQU “Professorat Lector” (2020) and ANECA “Profesor/a Contratado/a Doctor/a” (2025).
      </li>
    </ul>

    <h3>Scientific indicators (as reported)</h3>
    <ul>
      <li>
        Google Scholar metrics (as stated): ~1700 total citations; h-index 19; i10-index 23.
      </li>
    </ul>

    <h3>Service, memberships, and leadership</h3>
    <ul>
      <li>Member of ELLIS.</li>
      <li>Vice-president of the IAPR P&amp;P committee.</li>
      <li>Area Chair: NeurIPS 2024.</li>
      <li>Research team member: SGR 2014 and SGR 2021; group leadership within TECSAM network (Catalonia).</li>
      <li>Scientific outreach: workshops/challenges (with ChaLearn); outreach activities for high school and middle school students (UB/UAB initiatives).</li>
    </ul>

    <h3>International mobility</h3>
    <ul>
      <li>
        Postdoctoral: Aalborg University (Denmark), 01/04/2021–31/01/2023.
      </li>
      <li>
        Doctoral stay: Aalborg University (Denmark), 28/06/2018–28/09/2018.
      </li>
    </ul>
  </section>

  <footer class="small" style="margin-top: 28px; border-top: 1px solid #ccc; padding-top: 10px;">
    Last updated: <!-- Put a date here, e.g., 2025-12-15 -->.
    <br />
    <!-- OPTIONAL: Add a link to a PDF version of your CV in the repo. -->
  </footer>
</body>
</html>
